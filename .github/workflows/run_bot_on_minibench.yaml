name: Forecast on MiniBench tournament

on:
  workflow_dispatch:
    inputs:
      tournament_slug:
        description: 'MiniBench tournament slug (e.g., minibench)'
        required: false
        type: string
      tournament_id:
        description: 'MiniBench tournament ID (overrides repo var)'
        required: false
        type: string
      scheduling_frequency_minutes:
        description: 'Run frequency in minutes'
        required: false
        default: '60'
        type: string
  schedule:
    # Check every 15 minutes by default (MiniBench can open short-lived questions)
    - cron: '*/15 * * * *'

concurrency:
  group: minibench-forecasting
  cancel-in-progress: true

jobs:
  minibench_forecast:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    env:
      METACULUS_TOKEN: ${{ secrets.METACULUS_TOKEN }}
      OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      ASKNEWS_CLIENT_ID: ${{ secrets.ASKNEWS_CLIENT_ID }}
      ASKNEWS_SECRET: ${{ secrets.ASKNEWS_SECRET }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        id: setup-python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install poetry (with fallback)
        id: install-poetry
        continue-on-error: true
        uses: snok/install-poetry@v1
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true
          installer-parallel: true

      - name: Fallback to pip if poetry fails
        if: steps.install-poetry.outcome == 'failure'
        run: |
          python -m pip install --upgrade pip --timeout 60 --retries 3
          python -m pip install --timeout 60 --retries 3 poetry || true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}

      - name: ðŸ”§ Install dependencies with enhanced fallback
        id: install-deps
        run: |
          set -e

          echo "ðŸ” Checking Python environment..."
          python --version
          pip --version

          echo "ðŸ“¦ Attempting Poetry dependencies installation..."
          # Try Poetry first but immediately fall back to pip if ANY issues
          if poetry install --only main 2>/dev/null && poetry run python --version >/dev/null 2>&1; then
            echo "âœ… Poetry installation successful"
            POETRY_SUCCESS=true
          else
            echo "âš ï¸ Poetry installation failed or environment broken, falling back to pip immediately..."
            POETRY_SUCCESS=false
          fi

          # Immediate pip fallback with essential packages
          if [ "$POETRY_SUCCESS" = "false" ]; then
            echo "ðŸ”„ Installing essential packages via pip..."
            python -m pip install --upgrade pip

            # Install critical packages that are needed for the bot
            python -m pip install python-dotenv pydantic requests openai anthropic httpx aiofiles pyyaml typer pytest

            # Install forecasting_tools (critical for minibench bot)
            python -m pip install forecasting-tools || echo "âš ï¸ forecasting-tools not available via pip"

            # Try installing as editable package if possible
            python -m pip install -e . 2>/dev/null || echo "âš ï¸ Local package install failed"
          fi

          # Verify critical packages are available
          echo "ðŸ§ª Verifying critical dependencies..."
          python -c "
          import sys
          critical_packages = ['dotenv', 'pydantic', 'requests', 'openai']
          missing = []
          for pkg in critical_packages:
              try:
                  __import__(pkg)
                  print(f'âœ… {pkg}: available')
              except ImportError:
                  missing.append(pkg)
                  print(f'âŒ {pkg}: missing')

          if missing:
              print(f'âš ï¸ Installing missing critical packages: {missing}')
              import subprocess
              for pkg in missing:
                  try:
                      subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])
                      print(f'âœ… Emergency install of {pkg} successful')
                  except:
                      print(f'âŒ Emergency install of {pkg} failed')
          "


          echo "ðŸ“‹ Final package verification..."
          python -c "
          packages = ['dotenv', 'pydantic', 'requests', 'openai', 'forecasting_tools']
          for pkg in packages:
              try:
                  __import__(pkg)
                  print(f'âœ… {pkg}: imported successfully')
              except ImportError as e:
                  print(f'âŒ {pkg}: {e}')
          "

      - name: ðŸ§ª Debug Python environment
        run: |
          echo "ðŸ” Python Environment Debug:"
          python --version
          python -c "import sys; print('Python executable:', sys.executable)"
          python -c "import sys; print('Python path:', sys.path)"
          echo "ðŸ“¦ Installed packages:"
          pip list | head -20

          echo "ðŸ§ª Testing critical imports:"
          python -c "
          import sys
          try:
              import dotenv
              print('âœ… dotenv imported successfully')
          except ImportError as e:
              print(f'âŒ Failed to import dotenv: {e}')
              sys.exit(1)
          "

      - name: Resolve MiniBench tournament ID
        id: resolve_id
        run: |
          SLUG="${{ github.event.inputs.tournament_slug || vars.AIB_MINIBENCH_TOURNAMENT_SLUG || '' }}"
          MID="${{ github.event.inputs.tournament_id || vars.AIB_MINIBENCH_TOURNAMENT_ID || '' }}"
          if [ -n "$SLUG" ]; then
            echo "âœ… Using MiniBench tournament slug: $SLUG"
            echo "should_run=true" >> "$GITHUB_OUTPUT"
            echo "minibench_target=$SLUG" >> "$GITHUB_OUTPUT"
          elif [ -n "$MID" ]; then
            echo "âœ… Using MiniBench tournament ID: $MID"
            echo "should_run=true" >> "$GITHUB_OUTPUT"
            echo "minibench_target=$MID" >> "$GITHUB_OUTPUT"
          else
            echo "âš ï¸ MiniBench slug/ID is not configured. Set repo var AIB_MINIBENCH_TOURNAMENT_SLUG='minibench' or AIB_MINIBENCH_TOURNAMENT_ID, or pass input.";
            echo "should_run=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Write skipped summary (no tournament ID)
        if: steps.resolve_id.outputs.should_run != 'true'
        run: |
          cat > run_summary.json << 'JSON'
          {
            "run_mode": "tournament",
            "tournament_mode": "true",
            "tournament_id": "missing",
            "publish_reports": "false",
            "successful_forecasts": 0,
            "failed_forecasts": 0,
            "total_processed": 0,
            "status": "skipped",
            "reason": "AIB_MINIBENCH_TOURNAMENT_ID not configured and no input provided"
          }
          JSON
          echo "Wrote run_summary.json indicating skipped run."

      - name: Run MiniBench bot
        if: steps.resolve_id.outputs.should_run == 'true'
        id: run-bot
        run: |
          set -e

          # Robust Python runner detection with dependency verification
          echo "ðŸ” Determining Python execution method..."
          if poetry env info >/dev/null 2>&1 && poetry run python --version >/dev/null 2>&1 && poetry run python -c "import pydantic, requests" 2>/dev/null; then
            echo "ðŸš€ Poetry environment verified and working - using Poetry runner"
            PY_RUN="poetry run python"
          else
            echo "ðŸ Poetry environment not available or broken - using system Python"
            PY_RUN="python"
            export PYTHONPATH="${PWD}/src:${PYTHONPATH:-}"

            # Emergency dependency check for system Python
            echo "ðŸ§ª Verifying system Python has critical dependencies..."
            python -c "
            import sys
            missing_critical = []
            for pkg in ['dotenv', 'pydantic', 'requests']:
                try:
                    __import__(pkg)
                except ImportError:
                    missing_critical.append(pkg)

            if missing_critical:
                print(f'âŒ Critical packages missing: {missing_critical}')
                print('âš¡ Installing emergency dependencies...')
                import subprocess
                subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + missing_critical)
                print('âœ… Emergency dependencies installed')
            else:
                print('âœ… All critical dependencies available')
            " || echo "âš ï¸ Emergency dependency installation attempted"
          fi

          echo "ðŸš€ Running MiniBench bot for tournament ${{ steps.resolve_id.outputs.minibench_target }}"

          # Accept slug or ID in target envs
          if AIB_TOURNAMENT_SLUG=${{ steps.resolve_id.outputs.minibench_target }} \
             AIB_TOURNAMENT_ID=${{ steps.resolve_id.outputs.minibench_target }} \
             TOURNAMENT_MODE=true \
             PUBLISH_REPORTS=true \
             DRY_RUN=false \
             $PY_RUN main.py --mode tournament; then
            echo "âœ… Bot execution completed successfully"
            echo "success=true" >> "$GITHUB_OUTPUT"
          else
            echo "âŒ Bot execution failed"
            echo "success=false" >> "$GITHUB_OUTPUT"

            # Create fallback summary for failed executions
            cat > run_summary.json << EOF
          {
            "status": "failed",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "error": "Bot execution failed during MiniBench forecasting",
            "workflow_run": "${{ github.run_id }}",
            "commit": "${{ github.sha }}",
            "tournament_target": "${{ steps.resolve_id.outputs.minibench_target }}"
          }
          EOF

            exit 1
          fi
        env:
          LOG_LEVEL: INFO
          ENABLE_PROXY_CREDITS: true

      - name: Show run summary (if present)
        if: always()
        run: |
          if [ -f run_summary.json ]; then
            echo "ðŸ“„ Run Summary:"
            cat run_summary.json
          else
            echo "â„¹ï¸ run_summary.json not found."
          fi

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: minibench-run-${{ github.run_number }}
          path: |
            run_summary.json
            *.log
            logs/
          retention-days: 14
